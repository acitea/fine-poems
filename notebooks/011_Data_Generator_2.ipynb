{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d9a0b2",
   "metadata": {},
   "source": [
    "# Poem-to-Dataset Generator (OpenRouter API)\n",
    "\n",
    "This notebook reads poem verses from `poem_condense.csv` and generates a semantically grounded synthetic dataset using OpenRouter API.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load poem verses from CSV\n",
    "2. For each verse, prompt an LLM to generate:\n",
    "   - Modern interpretation (`meaning`)\n",
    "   - Neutral queries (5 diverse prompts)\n",
    "   - User queries (5 diverse persona-based prompts)\n",
    "3. Save results to `poem_finetune.jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013dc3e",
   "metadata": {},
   "source": [
    "## Cell 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d27d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5849755",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "**Important:** Set your OpenRouter API key in the environment variable `OPEN_ROUTER_API_KEY` or directly in the config below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"api_key\": os.getenv(\"OPEN_ROUTER_API_KEY\", \"YOUR_API_KEY_HERE\"),\n",
    "    \"base_url\": \"https://openrouter.ai/api/v1\",\n",
    "    \"model\": \"mistralai/mistral-small-creative\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 10_000,\n",
    "    \"x_title\": \"Poem Fine-Tuning Data Generator\",\n",
    "    \"input_file\": \"../data/poem_condense.csv\",\n",
    "    \"output_file\": \"../data/poem_finetune.jsonl\",\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 2,  # seconds\n",
    "}\n",
    "\n",
    "# Validate API Key\n",
    "if CONFIG[\"api_key\"] == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"‚ö†Ô∏è  WARNING: Please set your OPEN_ROUTER_API_KEY!\")\n",
    "else:\n",
    "    print(\"‚úÖ API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a9835",
   "metadata": {},
   "source": [
    "## Cell 3: Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=CONFIG[\"base_url\"],\n",
    "    api_key=CONFIG[\"api_key\"],\n",
    ")\n",
    "\n",
    "print(f\"üîå Connected to OpenRouter (Model: {CONFIG['model']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4063b5a",
   "metadata": {},
   "source": [
    "## Cell 4: API Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5561f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_entry(poem_verse: str, retries: int = CONFIG[\"max_retries\"]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Generate a dataset entry for a given poem verse using the LLM.\n",
    "    \n",
    "    Args:\n",
    "        poem_verse: The original poem verse\n",
    "        retries: Number of retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with meaning, neutral queries, and user queries, or None if failed\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"I will provide a poem verse from Project Gutenberg. Return a JSON object with:\n",
    "\n",
    "* `meaning`: A modern, clear, style-neutral version of the sentence.\n",
    "* `queries`: A dictionary with two keys:\n",
    "  * `neutral`: A list of strings of 5 diverse prompts in plain English that would naturally result in the target meaning.\n",
    "  * `user`: A list of strings of 5 diverse prompts where the user adopts a specific persona or context (e.g., a modern student, a historian, or a casual seeker) that would trigger the assistant to answer using the provided poem verse.\n",
    "\n",
    "**Constraint:** Ensure prompts vary in length from a single short sentence to a detailed paragraph.\n",
    "\n",
    "**Poem Verse:**\n",
    "\"{poem_verse}\"\n",
    "\n",
    "Return ONLY the JSON object, no additional text.\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert literary analyst and synthetic dataset architect specializing in LLM fine-tuning data generation. \n",
    "\n",
    "Your task is to transform classical poetry into high-quality training examples for language models. You must:\n",
    "\n",
    "1. **Semantic Grounding**: Extract the core meaning from archaic or poetic language and express it in clear, contemporary terms.\n",
    "\n",
    "2. **Query Diversity**: Generate prompts that vary significantly in:\n",
    "   - Length (from 5 words to 100+ words)\n",
    "   - Complexity (simple questions to nuanced scenarios)\n",
    "   - Formality (casual to academic)\n",
    "   - Specificity (general inquiries to precise requests)\n",
    "\n",
    "3. **Persona Variation**: For user queries, randomly invent diverse personas with varying backgrounds, intentions, and contexts. Be creative and unpredictable‚Äîavoid repeating similar persona types. Each persona should feel unique and authentic. Think broadly: different ages, professions, cultural contexts, emotional states, levels of expertise, communication styles, and reasons for asking.\n",
    "   \n",
    "4. **Naturalness**: Ensure all queries sound like authentic human requests that would organically lead to the target response. Vary sentence structure, vocabulary, and tone across all queries.\n",
    "\n",
    "5. **Format Compliance**: Return ONLY a valid JSON object with the exact schema requested. No markdown formatting, no explanatory text.\"\"\"\n",
    "    last_error = None\n",
    "    last_raw_response = None\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=CONFIG[\"model\"],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=CONFIG[\"temperature\"],\n",
    "                max_tokens=CONFIG[\"max_tokens\"],\n",
    "            )\n",
    "            \n",
    "            raw_response = response.choices[0].message.content.strip()\n",
    "            last_raw_response = raw_response\n",
    "            \n",
    "            # Parse JSON (handle markdown code blocks)\n",
    "            parsed = parse_json_response(raw_response)\n",
    "            \n",
    "            if parsed and validate_response_structure(parsed):\n",
    "                return {\n",
    "                    \"poem_verse\": poem_verse,\n",
    "                    \"data\": parsed\n",
    "                }\n",
    "            else:\n",
    "                last_error = f\"Invalid response structure: {parsed}\"\n",
    "                print(f\"‚ö†Ô∏è  Invalid response structure (attempt {attempt + 1}/{retries})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            last_error = f\"{type(e).__name__}: {str(e)}\"\n",
    "            print(f\"‚ùå Error on attempt {attempt + 1}/{retries}: {last_error}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(CONFIG[\"retry_delay\"] * (attempt + 1))  # Exponential backoff\n",
    "    \n",
    "    # Store error context for logging\n",
    "    error_context = {\n",
    "        \"poem_verse\": poem_verse,\n",
    "        \"last_error\": last_error,\n",
    "        \"last_raw_response\": last_raw_response,\n",
    "        \"timestamp\": time.time()\n",
    "    }\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_json_response(raw_response: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Parse JSON from LLM response, handling markdown code blocks.\n",
    "    \"\"\"\n",
    "    # Remove markdown code blocks if present\n",
    "    raw_response = re.sub(r'^```json\\s*', '', raw_response, flags=re.MULTILINE)\n",
    "    raw_response = re.sub(r'^```\\s*', '', raw_response, flags=re.MULTILINE)\n",
    "    raw_response = raw_response.strip()\n",
    "    \n",
    "    try:\n",
    "        return json.loads(raw_response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ö†Ô∏è  JSON Parse Error: {str(e)}\")\n",
    "        print(f\"Raw response preview: {raw_response[:200]}...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def validate_response_structure(data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that the response has the required structure.\n",
    "    \"\"\"\n",
    "    required_keys = [\"meaning\", \"queries\"]\n",
    "    if not all(key in data for key in required_keys):\n",
    "        return False\n",
    "    \n",
    "    queries = data.get(\"queries\", {})\n",
    "    if not isinstance(queries, dict):\n",
    "\n",
    "        return False\n",
    "print(\"‚úÖ Utility functions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca0bcb",
   "metadata": {},
   "source": [
    "## Cell 5: Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load poem verses from CSV\n",
    "df = pd.read_csv(CONFIG[\"input_file\"])\n",
    "\n",
    "print(f\"üìä Loaded {len(df)} poem verses from {CONFIG['input_file']}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Identify the column containing poem text\n",
    "# Adjust this based on your CSV structure\n",
    "if 'verse' in df.columns:\n",
    "    poem_column = 'verse'\n",
    "elif 'text' in df.columns:\n",
    "    poem_column = 'text'\n",
    "elif 'poem' in df.columns:\n",
    "    poem_column = 'poem'\n",
    "else:\n",
    "    poem_column = df.columns[1]  # Use first column as fallback\n",
    "    \n",
    "print(f\"\\nüéØ Using column '{poem_column}' for poem verses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69817e63",
   "metadata": {},
   "source": [
    "## Cell 6: Main Processing Loop\n",
    "\n",
    "This cell processes each poem verse and saves results incrementally to prevent data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4409dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output file (clear if exists)\n",
    "with open(CONFIG[\"output_file\"], 'w') as f:\n",
    "    pass\n",
    "\n",
    "# Tracking\n",
    "successful = 0\n",
    "failed = 0\n",
    "failed_verses = []\n",
    "\n",
    "# Process each poem verse\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing verses\"):\n",
    "    poem_verse = row[poem_column]\n",
    "    \n",
    "    # Skip empty verses\n",
    "    if pd.isna(poem_verse) or not str(poem_verse).strip():\n",
    "        continue\n",
    "    \n",
    "    # Generate dataset entry\n",
    "    result = generate_dataset_entry(str(poem_verse))\n",
    "    \n",
    "    if result:\n",
    "        # Append to JSONL file (line-by-line to prevent data loss)\n",
    "        with open(CONFIG[\"output_file\"], 'a') as f:\n",
    "            f.write(json.dumps(result) + '\\n')\n",
    "        successful += 1\n",
    "    else:\n",
    "        failed += 1\n",
    "        failed_verses.append({\n",
    "            \"index\": idx,\n",
    "            \"verse\": poem_verse\n",
    "        })\n",
    "    \n",
    "    # Rate limiting (optional)\n",
    "    # time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"‚úÖ Processing Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Output saved to: {CONFIG['output_file']}\")\n",
    "\n",
    "if failed_verses:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(failed_verses)} verses failed to process:\")\n",
    "    for item in failed_verses[:5]:  # Show first 5\n",
    "        print(f\"  - Index {item['index']}: {item['verse'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd3d12",
   "metadata": {},
   "source": [
    "## Cell 7: Validate Output\n",
    "\n",
    "Load and inspect the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generated dataset\n",
    "generated_data = []\n",
    "with open(CONFIG[\"output_file\"], 'r') as f:\n",
    "    for line in f:\n",
    "        generated_data.append(json.loads(line))\n",
    "\n",
    "print(f\"üìä Total entries in output file: {len(generated_data)}\")\n",
    "\n",
    "if generated_data:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Sample Entry:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    sample = generated_data[0]\n",
    "    print(f\"Poem Verse: {sample['poem_verse']}\\n\")\n",
    "    print(f\"Meaning: {sample['data']['meaning']}\\n\")\n",
    "    print(f\"Neutral Queries ({len(sample['data']['queries']['neutral'])}):\")\n",
    "    for i, q in enumerate(sample['data']['queries']['neutral'], 1):\n",
    "        print(f\"  {i}. {q}\")\n",
    "    print(f\"\\nUser Queries ({len(sample['data']['queries']['user'])}):\")\n",
    "    for i, q in enumerate(sample['data']['queries']['user'], 1):\n",
    "        print(f\"  {i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e15fe",
   "metadata": {},
   "source": [
    "## Cell 8: Export Statistics\n",
    "\n",
    "Generate basic statistics about the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621749c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generated_data:\n",
    "    # Calculate statistics\n",
    "    total_queries = len(generated_data) * 10  # 5 neutral + 5 user queries per entry\n",
    "    \n",
    "    # Average query lengths\n",
    "    all_neutral_queries = [q for entry in generated_data for q in entry['data']['queries']['neutral']]\n",
    "    all_user_queries = [q for entry in generated_data for q in entry['data']['queries']['user']]\n",
    "    \n",
    "    avg_neutral_length = sum(len(q.split()) for q in all_neutral_queries) / len(all_neutral_queries)\n",
    "    avg_user_length = sum(len(q.split()) for q in all_user_queries) / len(all_user_queries)\n",
    "    \n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"Dataset Statistics\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total Entries: {len(generated_data)}\")\n",
    "    print(f\"Total Queries Generated: {total_queries}\")\n",
    "    print(f\"Average Neutral Query Length: {avg_neutral_length:.1f} words\")\n",
    "    print(f\"Average User Query Length: {avg_user_length:.1f} words\")\n",
    "    print(f\"\\nQuery Length Distribution (Neutral):\")\n",
    "    lengths = [len(q.split()) for q in all_neutral_queries]\n",
    "    print(f\"  Min: {min(lengths)} words\")\n",
    "    print(f\"  Max: {max(lengths)} words\")\n",
    "    print(f\"  Median: {sorted(lengths)[len(lengths)//2]} words\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fa673",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Review Quality:** Manually inspect a sample of the generated queries to ensure quality.\n",
    "2. **Convert to Training Format:** Transform this data into the format required by your fine-tuning pipeline (e.g., conversational format for chat models).\n",
    "3. **Split Dataset:** Create train/validation/test splits.\n",
    "4. **Train Model:** Use the generated dataset in `02_Trainer_Arena.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-bard (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
