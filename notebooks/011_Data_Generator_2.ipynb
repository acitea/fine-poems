{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d9a0b2",
   "metadata": {},
   "source": [
    "# Poem-to-Dataset Generator (OpenRouter API)\n",
    "\n",
    "This notebook reads poem verses from `poem_condense.csv` and generates a semantically grounded synthetic dataset using OpenRouter API.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load poem verses from CSV\n",
    "2. For each verse, prompt an LLM to generate:\n",
    "   - Modern interpretation (`meaning`)\n",
    "   - Neutral queries (5 diverse prompts)\n",
    "   - User queries (5 diverse persona-based prompts)\n",
    "3. Save results to `poem_finetune.jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e013dc3e",
   "metadata": {},
   "source": [
    "## Cell 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d27d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Optional, Tuple\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json_repair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5849755",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "**Important:** Set your OpenRouter API key in the environment variable `OPEN_ROUTER_API_KEY` or directly in the config below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a033bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"api_key\": os.getenv(\"OPEN_ROUTER_API_KEY\", \"YOUR_API_KEY_HERE\"),\n",
    "    \"base_url\": \"https://openrouter.ai/api/v1\",\n",
    "    \"model\": \"mistralai/mistral-small-creative\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 10_000,\n",
    "    \"http_referer\": \"https://github.com/acitea/fine-poems\",\n",
    "    \"x_title\": \"Poem Fine-Tuning Data Generator\",\n",
    "    \"input_file\": \"../data/poem_condense.csv\",\n",
    "    \"output_file\": \"../data/poem_finetune.jsonl\",\n",
    "    \"failed_output_file\": \"../data/poem_finetune_failed.jsonl\",\n",
    "    \"max_retries\": 3,\n",
    "    \"retry_delay\": 2,\n",
    "    \"concurrency\": 20,\n",
    "}\n",
    "\n",
    "# Validate API Key\n",
    "if CONFIG[\"api_key\"] == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"âš ï¸  WARNING: Please set your OPEN_ROUTER_API_KEY!\")\n",
    "else:\n",
    "    print(\"âœ… API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a9835",
   "metadata": {},
   "source": [
    "## Cell 3: Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0190fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Œ Connected to OpenRouter (Model: mistralai/mistral-small-creative)\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=CONFIG[\"base_url\"],\n",
    "    api_key=CONFIG[\"api_key\"],\n",
    ")\n",
    "\n",
    "print(f\"ðŸ”Œ Connected to OpenRouter (Model: {CONFIG['model']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4063b5a",
   "metadata": {},
   "source": [
    "## Cell 4: API Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5561f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset_entry(poem_verse: str, retries: int = CONFIG[\"max_retries\"]) -> Tuple[Optional[Dict], Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Generate a dataset entry for a given poem verse using the LLM.\n",
    "\n",
    "    Returns:\n",
    "        (success_record, failure_record)\n",
    "        - success_record: {\"poem_verse\": ..., \"data\": ...} when successful\n",
    "        - failure_record: diagnostic payload when all retries fail\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"I will provide a poem verse from Project Gutenberg. Return a JSON object with:\n",
    "\n",
    "* `meaning`: A modern, clear, style-neutral version of the sentence.\n",
    "* `queries`: A dictionary with two keys:\n",
    "  * `neutral`: A list of strings of 5 diverse prompts in plain English that would naturally result in the target meaning.\n",
    "  * `user`: A list of strings of 5 diverse prompts where the user adopts a specific persona or context that would trigger the assistant to answer using the provided poem verse.\n",
    "\n",
    "**Constraint:** Ensure prompts vary in length from a single short sentence to a detailed paragraph.\n",
    "\n",
    "**Poem Verse:**\n",
    "\"{poem_verse}\"\n",
    "\n",
    "Return ONLY the JSON object, no additional text.\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert literary analyst and synthetic dataset architect specializing in LLM fine-tuning data generation. \n",
    "\n",
    "Your task is to transform classical poetry into high-quality training examples for language models. You must:\n",
    "\n",
    "1. **Semantic Grounding**: Extract the core meaning from archaic or poetic language and express it in clear, contemporary terms.\n",
    "\n",
    "2. **Query Diversity**: Generate prompts that vary significantly in:\n",
    "   - Length (from 5 words to 100+ words)\n",
    "   - Complexity (simple questions to nuanced scenarios)\n",
    "   - Formality (casual to academic)\n",
    "   - Specificity (general inquiries to precise requests)\n",
    "\n",
    "3. **Persona Variation**: For user queries, randomly invent diverse personas with varying backgrounds, intentions, and contexts. Be creative and unpredictableâ€”avoid repeating similar persona types. Each persona should feel unique and authentic. Think broadly: different ages, professions, cultural contexts, emotional states, levels of expertise, communication styles, and reasons for asking.\n",
    "   \n",
    "4. **Naturalness**: Ensure all queries sound like authentic human requests that would organically lead to the target response. Vary sentence structure, vocabulary, and tone across all queries.\n",
    "\n",
    "5. **Format Compliance**: Return ONLY a valid JSON object with the exact schema requested. No markdown formatting, no explanatory text.\"\"\"\n",
    "    last_error = None\n",
    "    last_raw_response = None\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=CONFIG[\"model\"],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                temperature=CONFIG[\"temperature\"],\n",
    "                max_tokens=CONFIG[\"max_tokens\"],\n",
    "            )\n",
    "\n",
    "            raw_response = (response.choices[0].message.content or \"\").strip()\n",
    "            last_raw_response = raw_response\n",
    "\n",
    "            parsed = parse_json_response(raw_response)\n",
    "            if parsed and validate_response_structure(parsed):\n",
    "                return {\"poem_verse\": poem_verse, \"data\": parsed}, None\n",
    "\n",
    "            last_error = \"Invalid response structure\"\n",
    "\n",
    "        except Exception as e:\n",
    "            last_error = f\"{type(e).__name__}: {str(e)}\"\n",
    "\n",
    "        if attempt < retries - 1:\n",
    "            time.sleep(CONFIG[\"retry_delay\"] * (attempt + 1))\n",
    "\n",
    "    failure_record = {\n",
    "        \"poem_verse\": poem_verse,\n",
    "        \"last_error\": last_error,\n",
    "        \"last_raw_response\": last_raw_response,\n",
    "        \"timestamp\": time.time(),\n",
    "    }\n",
    "    return None, failure_record\n",
    "\n",
    "\n",
    "def parse_json_response(raw_response: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Parse JSON from LLM response using json_repair for robust extraction.\n",
    "    Handles markdown, control chars, incomplete JSON, and common formatting issues.\n",
    "    \"\"\"\n",
    "    # Remove markdown code blocks\n",
    "    raw_response = re.sub(r\"^```json\\s*\", \"\", raw_response, flags=re.MULTILINE)\n",
    "    raw_response = re.sub(r\"^```\\s*\", \"\", raw_response, flags=re.MULTILINE)\n",
    "    raw_response = re.sub(r\"```\\s*$\", \"\", raw_response, flags=re.MULTILINE)\n",
    "    raw_response = raw_response.strip()\n",
    "\n",
    "    # Extract JSON object boundaries\n",
    "    start_idx = raw_response.find(\"{\")\n",
    "    end_idx = raw_response.rfind(\"}\")\n",
    "\n",
    "    if start_idx == -1 or end_idx == -1 or end_idx <= start_idx:\n",
    "        print(f\"âš ï¸  No JSON object found in response\")\n",
    "        print(f\"Full response:\\n{raw_response}\")\n",
    "        return None\n",
    "\n",
    "    json_str = raw_response[start_idx : end_idx + 1]\n",
    "\n",
    "    try:\n",
    "        repaired = json_repair.loads(json_str)\n",
    "        return repaired\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  JSON repair and parse failed: {str(e)}\")\n",
    "        print(f\"Full extracted JSON:\\n{json_str}\")\n",
    "        return None\n",
    "\n",
    "def validate_response_structure(data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that the response has the required structure.\n",
    "    \"\"\"\n",
    "    required_keys = [\"meaning\", \"queries\"]\n",
    "    if not all(key in data for key in required_keys):\n",
    "        return False\n",
    "\n",
    "    queries = data.get(\"queries\", {})\n",
    "    if not isinstance(queries, dict):\n",
    "        return False\n",
    "\n",
    "    if \"neutral\" not in queries or \"user\" not in queries:\n",
    "        return False\n",
    "\n",
    "    if not isinstance(queries[\"neutral\"], list) or len(queries[\"neutral\"]) != 5:\n",
    "        return False\n",
    "\n",
    "    if not isinstance(queries[\"user\"], list) or len(queries[\"user\"]) != 5:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"âœ… Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca0bcb",
   "metadata": {},
   "source": [
    "## Cell 5: Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed0e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loaded 199002 poem verses from ../data/poem_condense.csv\n",
      "Columns: ['Unnamed: 0', 'Verse', 'Meter', 'char_count']\n",
      "\n",
      "First few rows:\n",
      "   Unnamed: 0                                              Verse   Meter  \\\n",
      "0           0          ah why this boding start this sudden pain  iambic   \n",
      "1           1   that wings my pulse and shoots from vein to vein  iambic   \n",
      "2           2          what mean regardless of yon midnight bell  iambic   \n",
      "3           3     these earthborn visions saddening o'er my cell  iambic   \n",
      "4           4  what strange disorder prompts these thoughts t...  iambic   \n",
      "\n",
      "   char_count  \n",
      "0           6  \n",
      "1           6  \n",
      "2           6  \n",
      "3           6  \n",
      "4           6  \n",
      "\n",
      "ðŸŽ¯ Using column 'Verse' for poem verses\n"
     ]
    }
   ],
   "source": [
    "# Load poem verses from CSV\n",
    "df = pd.read_csv(CONFIG[\"input_file\"])\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {len(df)} poem verses from {CONFIG['input_file']}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Identify the column containing poem text\n",
    "# Adjust this based on your CSV structure\n",
    "if 'verse' in df.columns:\n",
    "    poem_column = 'verse'\n",
    "elif 'text' in df.columns:\n",
    "    poem_column = 'text'\n",
    "elif 'poem' in df.columns:\n",
    "    poem_column = 'poem'\n",
    "else:\n",
    "    poem_column = df.columns[1]  # Use first column as fallback\n",
    "    \n",
    "print(f\"\\nðŸŽ¯ Using column '{poem_column}' for poem verses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69817e63",
   "metadata": {},
   "source": [
    "## Cell 6: Main Processing Loop\n",
    "\n",
    "This cell processes each poem verse and saves results incrementally to prevent data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4409dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running 199002 requests with concurrency=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verses:   3%|â–Ž         | 6557/199002 [44:43<20:50:50,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No JSON object found in response\n",
      "Full response:\n",
      "{\n",
      "  \"meaning\": \"From the moment the Senate gained authority, both men and women became aware of its influence and the political power it wielded.\",\n",
      "\n",
      "  \"queries\": {\n",
      "    \"neutral\": [\n",
      "      \"How did the Senateâ€™s rise to power\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verses:   5%|â–         | 9873/199002 [1:07:36<14:36:07,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No JSON object found in response\n",
      "Full response:\n",
      "{\n",
      "  \"meaning\": \"I assert my right to be included in the count or recognition of something important, whether itâ€™s a group, a legacy, or a meaningful contribution.\",\n",
      "\n",
      "  \"queries\": {\n",
      "    \"neutral\": [\n",
      "      \"What does it mean to 'claim a part' in a collective effort or legacy?\",\n",
      "      \"How can someone assert their place in a shared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verses:   5%|â–Œ         | 10893/199002 [1:14:39<29:11:38,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  No JSON object found in response\n",
      "Full response:\n",
      "{\n",
      "  \"meaning\": \"The babyâ€™s innocent, joyful smile disarmed even those who disliked or opposed her, softening their hostility with its purity and charm.\",\n",
      "\n",
      "  \"queries\": {\n",
      "    \"neutral\": [\n",
      "      \"How can a babyâ€™s smile change someoneâ€™s attitude toward them?\",\n",
      "      \"What does it mean when a childâ€™s happiness seems to melt away anger or resentment?\",\n",
      "      \"Describe a moment where innocence had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing verses:   7%|â–‹         | 13468/199002 [1:32:53<21:19:33,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize output files (clear if exist)\n",
    "with open(CONFIG[\"output_file\"], \"w\") as f:\n",
    "    pass\n",
    "with open(CONFIG[\"failed_output_file\"], \"w\") as f:\n",
    "    pass\n",
    "\n",
    "# Tracking\n",
    "successful = 0\n",
    "failed = 0\n",
    "failed_verses = []\n",
    "\n",
    "# Build task list first (skip empty verses)\n",
    "tasks = []\n",
    "for idx, row in df.iterrows():\n",
    "    poem_verse = row[poem_column]\n",
    "    if pd.isna(poem_verse) or not str(poem_verse).strip():\n",
    "        continue\n",
    "    tasks.append((int(idx), str(poem_verse)))\n",
    "\n",
    "print(f\"ðŸš€ Running {len(tasks)} requests with concurrency={CONFIG['concurrency']}\")\n",
    "\n",
    "# Execute concurrently and write results as they complete\n",
    "with ThreadPoolExecutor(max_workers=CONFIG[\"concurrency\"]) as executor:\n",
    "    future_to_task = {\n",
    "        executor.submit(generate_dataset_entry, verse): (idx, verse)\n",
    "        for idx, verse in tasks\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_task), total=len(future_to_task), desc=\"Processing verses\"):\n",
    "        idx, poem_verse = future_to_task[future]\n",
    "\n",
    "        try:\n",
    "            result, failure_record = future.result()\n",
    "        except Exception as e:\n",
    "            result = None\n",
    "            failure_record = {\n",
    "                \"poem_verse\": poem_verse,\n",
    "                \"last_error\": f\"FutureExecutionError: {type(e).__name__}: {str(e)}\",\n",
    "                \"last_raw_response\": None,\n",
    "                \"timestamp\": time.time(),\n",
    "            }\n",
    "\n",
    "        if result:\n",
    "            with open(CONFIG[\"output_file\"], \"a\") as f:\n",
    "                f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "            failed_payload = {\n",
    "                \"index\": idx,\n",
    "                \"verse\": poem_verse,\n",
    "                \"failure\": failure_record,\n",
    "            }\n",
    "            failed_verses.append(failed_payload)\n",
    "\n",
    "            with open(CONFIG[\"failed_output_file\"], \"a\") as f:\n",
    "                f.write(json.dumps(failed_payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"âœ… Processing Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Output saved to: {CONFIG['output_file']}\")\n",
    "print(f\"Failures saved to: {CONFIG['failed_output_file']}\")\n",
    "\n",
    "if failed_verses:\n",
    "    print(f\"\\nâš ï¸  {len(failed_verses)} verses failed to process:\")\n",
    "    for item in failed_verses[:5]:\n",
    "        print(f\"  - Index {item['index']}: {item['verse'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd3d12",
   "metadata": {},
   "source": [
    "## Cell 7: Validate Output\n",
    "\n",
    "Load and inspect the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generated dataset\n",
    "generated_data = []\n",
    "with open(CONFIG[\"output_file\"], 'r') as f:\n",
    "    for line in f:\n",
    "        generated_data.append(json.loads(line))\n",
    "\n",
    "print(f\"ðŸ“Š Total entries in output file: {len(generated_data)}\")\n",
    "\n",
    "if generated_data:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Sample Entry:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    sample = generated_data[0]\n",
    "    print(f\"Poem Verse: {sample['poem_verse']}\\n\")\n",
    "    print(f\"Meaning: {sample['data']['meaning']}\\n\")\n",
    "    print(f\"Neutral Queries ({len(sample['data']['queries']['neutral'])}):\")\n",
    "    for i, q in enumerate(sample['data']['queries']['neutral'], 1):\n",
    "        print(f\"  {i}. {q}\")\n",
    "    print(f\"\\nUser Queries ({len(sample['data']['queries']['user'])}):\")\n",
    "    for i, q in enumerate(sample['data']['queries']['user'], 1):\n",
    "        print(f\"  {i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e15fe",
   "metadata": {},
   "source": [
    "## Cell 8: Export Statistics\n",
    "\n",
    "Generate basic statistics about the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621749c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generated_data:\n",
    "    # Calculate statistics\n",
    "    total_queries = len(generated_data) * 10  # 5 neutral + 5 user queries per entry\n",
    "    \n",
    "    # Average query lengths\n",
    "    all_neutral_queries = [q for entry in generated_data for q in entry['data']['queries']['neutral']]\n",
    "    all_user_queries = [q for entry in generated_data for q in entry['data']['queries']['user']]\n",
    "    \n",
    "    avg_neutral_length = sum(len(q.split()) for q in all_neutral_queries) / len(all_neutral_queries)\n",
    "    avg_user_length = sum(len(q.split()) for q in all_user_queries) / len(all_user_queries)\n",
    "    \n",
    "    print(f\"{'='*50}\")\n",
    "    print(\"Dataset Statistics\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total Entries: {len(generated_data)}\")\n",
    "    print(f\"Total Queries Generated: {total_queries}\")\n",
    "    print(f\"Average Neutral Query Length: {avg_neutral_length:.1f} words\")\n",
    "    print(f\"Average User Query Length: {avg_user_length:.1f} words\")\n",
    "    print(f\"\\nQuery Length Distribution (Neutral):\")\n",
    "    lengths = [len(q.split()) for q in all_neutral_queries]\n",
    "    print(f\"  Min: {min(lengths)} words\")\n",
    "    print(f\"  Max: {max(lengths)} words\")\n",
    "    print(f\"  Median: {sorted(lengths)[len(lengths)//2]} words\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fa673",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Review Quality:** Manually inspect a sample of the generated queries to ensure quality.\n",
    "2. **Convert to Training Format:** Transform this data into the format required by your fine-tuning pipeline (e.g., conversational format for chat models).\n",
    "3. **Split Dataset:** Create train/validation/test splits.\n",
    "4. **Train Model:** Use the generated dataset in `02_Trainer_Arena.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-bard (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
