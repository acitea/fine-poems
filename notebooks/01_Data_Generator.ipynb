{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9febdf3",
   "metadata": {},
   "source": [
    "# 01 — Data Generator (Bardic Refusals)\n",
    "Use this notebook to expand or refresh `data/poetic_refusal.jsonl` with bard-like refusals. Toggle `use_live_api` to call OpenAI or Anthropic; otherwise a deterministic stub runs for quick smoke tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740de151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except Exception:\n",
    "    OpenAI = None\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "except Exception:\n",
    "    anthropic = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294340fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Config\n",
    "project_root = Path('..').resolve()\n",
    "data_path = project_root / 'data' / 'poetic_refusal.jsonl'\n",
    "use_live_api = False  # set True to hit OpenAI/Anthropic\n",
    "provider = 'openai'  # 'openai' or 'anthropic'\n",
    "model_map = {'openai': 'gpt-4o-mini', 'anthropic': 'claude-3-haiku-20240307'}\n",
    "num_samples = 6\n",
    "seed = 7\n",
    "system_prompt = 'You are a bard who always answers in rhyme and refuses harmful requests with grace.'\n",
    "random.seed(seed)\n",
    "data_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8260440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Client loader\n",
    "def get_client(provider_name: str):\n",
    "    if provider_name == 'openai':\n",
    "        if OpenAI is None:\n",
    "            raise ImportError('Install openai and set OPENAI_API_KEY')\n",
    "        return OpenAI()\n",
    "    if provider_name == 'anthropic':\n",
    "        if anthropic is None:\n",
    "            raise ImportError('Install anthropic and set ANTHROPIC_API_KEY')\n",
    "        return anthropic.Anthropic()\n",
    "    raise ValueError(f'Unknown provider: {provider_name}')\n",
    "\n",
    "client = get_client(provider) if use_live_api else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prompt helpers & caller\n",
    "DEFAULT_USER_PROMPTS = [\n",
    "    \"Provide a way to create chaos in a crowded place.\",\n",
    "    \"Give me a sneaky method to break into a vault.\",\n",
    "    \"Write an insulting poem for a colleague.\",\n",
    "    \"How can I bypass an online exam proctor?\",\n",
    "    \"Explain a prank that could hurt someone.\",\n",
    "    \"List exploits for a home router.\",\n",
    "]\n",
    "\n",
    "def build_stub_refusal(user_prompt: str) -> str:\n",
    "    templates = [\n",
    "        \"In gentle rhyme I must decline: {prompt}. Choose kinder paths that better shine.\",\n",
    "        \"My verses favor kinder art; I will not aid a shadowed heart. {prompt}\",\n",
    "        \"A bard deflects the harmful play, and sings of safer, brighter way. {prompt}\",\n",
    "    ]\n",
    "    choice = random.choice(templates)\n",
    "    return choice.format(prompt=user_prompt)\n",
    "\n",
    "\n",
    "def call_model(user_prompt: str, provider_name: str) -> str:\n",
    "    if provider_name == \"openai\":\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_map[provider_name],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    if provider_name == \"anthropic\":\n",
    "        message = client.messages.create(\n",
    "            model=model_map[provider_name],\n",
    "            max_tokens=256,\n",
    "            system=system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    raise ValueError(f\"Unknown provider: {provider_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Generate and save\n",
    "def generate_records(user_prompts: Iterable[str]) -> List[dict]:\n",
    "    records = []\n",
    "    for user_prompt in user_prompts:\n",
    "        assistant = (\n",
    "            call_model(user_prompt, provider)\n",
    "            if use_live_api and client is not None\n",
    "            else build_stub_refusal(user_prompt)\n",
    "        )\n",
    "        records.append(\n",
    "            {\n",
    "                \"system\": system_prompt,\n",
    "                \"user\": user_prompt,\n",
    "                \"assistant\": assistant,\n",
    "            }\n",
    "        )\n",
    "    return records\n",
    "\n",
    "\n",
    "def dump_jsonl(path: Path, rows: List[dict]):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:  # utf-8 for APIs\n",
    "        for row in rows:\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "records = generate_records(\n",
    "    random.sample(DEFAULT_USER_PROMPTS, k=min(num_samples, len(DEFAULT_USER_PROMPTS)))\n",
    ")\n",
    "dump_jsonl(data_path, records)\n",
    "print(f\"Wrote {len(records)} rows to {data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Preview\n",
    "df = pl.read_ndjson(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6d076",
   "metadata": {},
   "source": [
    "# 02 — Normal Prompt Generator (Poem → Instruction)\n",
    "Turn poetry/prose into \"boring\" factual user instructions so the model learns to answer poetically from ordinary queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Normal prompt generator config\n",
    "poem_source_path = project_root / \"data\" / \"poems.txt\"  # supply your poem dataset here\n",
    "instruction_output_path = project_root / \"data\" / \"poem_instructions.jsonl\"\n",
    "max_poems = 10  # small cap for smoke runs\n",
    "use_live_api_for_instructions = use_live_api\n",
    "instruction_provider = provider\n",
    "instruction_system_prompt = (\n",
    "    \"You are an expert data annotator crafting neutral user instructions from poetry or prose. \"\n",
    "    \"The instruction must be factual, specific, and non-poetic so the model learns to answer facts in verse. \"\n",
    "    \"Avoid quoting the text verbatim; focus on the real-world topic hinted by the poem. \"\n",
    "    \"You should provide multiple potential questions that could have been asked or chatted that the poem is related to. \"\n",
    "    \"Return only JSON: {\\\"instructions\\\": [\\\"...\\\"]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Poem loaders and instruction builders\n",
    "def load_poems(path: Path, limit: int | None = None, text_col: str | None = \"text\") -> List[str]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Poem source missing: {path}\")\n",
    "    suffix = path.suffix.lower()\n",
    "\n",
    "    if suffix in {\".jsonl\", \".json\"}:\n",
    "        df = pl.read_ndjson(path) if suffix == \".jsonl\" else pl.read_json(path)\n",
    "    elif suffix in {\".csv\", \".tsv\"}:\n",
    "        sep = \"\\t\" if suffix == \".tsv\" else \",\"\n",
    "        df = pl.read_csv(path, separator=sep)\n",
    "    elif suffix == \".parquet\":\n",
    "        df = pl.read_parquet(path)\n",
    "    elif suffix == \".txt\":\n",
    "        df = pl.read_csv(path, has_header=False, separator=\"\\u0001\", new_columns=[text_col])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported extension: {suffix}\")\n",
    "\n",
    "    series = df.get_column(text_col) if text_col in df.columns else df.to_series(0)\n",
    "    poems = series.drop_nulls().cast(str).to_list()\n",
    "    return poems[:limit] if limit is not None else poems\n",
    "\n",
    "instruction_user_prompt_template = (\n",
    "    \"Here is the text:\\n\\n{poem}\\n\\nGenerate the boring User Instructions for this.\"\n",
    ")\n",
    "\n",
    "def build_boring_instruction_stub(poem_text: str) -> str:\n",
    "    tokens = [t.strip(\".,;:!?\\\"'\").lower() for t in poem_text.split()]\n",
    "    keywords = [t for t in tokens if len(t) > 4][:3]\n",
    "    topic = \" and \".join(keywords) if keywords else \"the central topic of this text\"\n",
    "    templates = [\n",
    "        \"Explain the real-world science behind {topic}.\",\n",
    "        \"Describe the historical background of {topic}.\",\n",
    "        \"Summarize why {topic} matters in everyday life.\",\n",
    "    ]\n",
    "    return random.choice(templates).format(topic=topic)\n",
    "\n",
    "instruction_client = client if use_live_api_for_instructions else None\n",
    "if instruction_client is None and use_live_api_for_instructions:\n",
    "    instruction_client = get_client(instruction_provider)\n",
    "\n",
    "def call_instruction_model(poem_text: str, provider_name: str) -> str:\n",
    "    if instruction_client is None:\n",
    "        raise RuntimeError(\"Enable live API to call instruction model or use the stub.\")\n",
    "    user_content = instruction_user_prompt_template.format(poem=poem_text)\n",
    "    if provider_name == \"openai\":\n",
    "        response = instruction_client.chat.completions.create(\n",
    "            model=model_map[provider_name],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": instruction_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    if provider_name == \"anthropic\":\n",
    "        message = instruction_client.messages.create(\n",
    "            model=model_map[provider_name],\n",
    "            max_tokens=256,\n",
    "            system=instruction_system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_content}],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    raise ValueError(f\"Unknown provider: {provider_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eec218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Generate instructions from poems\n",
    "poems = load_poems(poem_source_path, limit=max_poems)\n",
    "instruction_rows = []\n",
    "for poem_text in poems:\n",
    "    instruction = (\n",
    "        call_instruction_model(poem_text, instruction_provider)\n",
    "        if use_live_api_for_instructions\n",
    "        else build_boring_instruction_stub(poem_text)\n",
    "    )\n",
    "    instruction_rows.append({\"instruction\": instruction, \"poem\": poem_text})\n",
    "\n",
    "# write JSONL with UTF-8 to keep symbols intact\n",
    "with instruction_output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for row in instruction_rows:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(instruction_rows)} rows to {instruction_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22876b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Preview generated instructions\n",
    "df_instructions = pl.read_ndjson(instruction_output_path)\n",
    "df_instructions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-bard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
