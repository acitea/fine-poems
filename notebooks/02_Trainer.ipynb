{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9706a11",
   "metadata": {},
   "source": [
    "# 02 â€” Trainer Arena (LoRA vs DoRA)\n",
    "\n",
    "Sequentially trains two adapters (LoRA then DoRA) using enriched poem dataset with persona metadata.\n",
    "Each run cleans up VRAM before the next begins.\n",
    "\n",
    "**Data features**: Uses persona context from user queries to train the model to respond to different personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e843d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0224 00:15:46.918000 10540 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import gc\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f13dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Config loaded. Data: poem_finetune_13000.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Config\n",
    "project_root = Path('..').resolve()\n",
    "data_path = project_root / 'data' / 'poem_finetune_13000.jsonl'  # Use enriched dataset with persona data\n",
    "output_root = project_root / 'outputs'\n",
    "base_model_id = 'unsloth/Mistral-Nemo-Instruct-2407'\n",
    "max_seq_length = 2048\n",
    "learning_rate = 2e-4\n",
    "batch_size = 2\n",
    "num_epochs = 1\n",
    "gradient_accumulation = 4\n",
    "\n",
    "configs = [\n",
    "    {\"name\": \"lora\", \"dora\": False},\n",
    "    {\"name\": \"dora\", \"dora\": True},\n",
    "]\n",
    "\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Config loaded. Data: {data_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enriched dataset...\n",
      "\n",
      "ðŸ“Š Dataset Transformation Summary:\n",
      "   Neutral queries:            67340\n",
      "   User queries (enriched):    59992\n",
      "   User queries (fallback):    209\n",
      "   Skipped:                    203\n",
      "   âžœ Total examples:           127541\n",
      "\n",
      "âœ… Dataset loaded: 31885 examples\n",
      "\n",
      "Sample training example:\n",
      "\n",
      "---Sample 1 ---\n",
      "  User:      Why does overthinking a difficult situation often make it feel worse?\n",
      "Context: I should mean that Even if you keep thinking about it, the sadness or problem wonâ€™t go awayâ€”it will remain a source of suffering.]\n",
      "  Assistant: if thou will't ruminate 'tis still a woe\n",
      "\n",
      "---Sample 2 ---\n",
      "  User:      bro. i just saw [redacted] at the dance and i legit stopped breathing for a sec. how do i say that without sounding like a total simp? like, i wasnâ€™t expecting her to look like that and now iâ€™m just standing here like ??? help.\n",
      "Context: I should mean that He looked at the beautiful woman with astonishment, as if he couldnâ€™t believe what he was seeing.]\n",
      "  Assistant: he gaz'd on the fair with surprize\n",
      "\n",
      "---Sample 3 ---\n",
      "  User:      If someone is 'holding forth against abuse,' what kind of situation or behavior are they likely addressing?\n",
      "Context: I should mean that Someone will discover this person passionately speaking out against mistreatment or corruption, likely in a public or intellectual setting where theyâ€™re critiquing harmful practices or defending those who are wronged.]\n",
      "  Assistant: shall find him holding forth against abuse\n",
      "\n",
      "---Sample 4 ---\n",
      "  User:      I spent decades watching my wife fade away, day after day, never knowing if it would be the last. How do I put into words what it was likeâ€”this never-ending weight, this... this *thing* that never left me, even when I slept? I donâ€™t want to sound dramatic, but I need her to understand. Thereâ€™s no other way to say it, is there?\n",
      "Context: I should mean that The relentless, exhausting effort required to endure something difficult over a long period of time, often without immediate relief or reward.]\n",
      "  Assistant: what painful patience what incessant care\n",
      "\n",
      "---Sample 5 ---\n",
      "  User:      Describe the visual effect of a sunset in the western sky.\n",
      "Context: I should mean that When the sun sets and paints the western sky with rich shades of purple, signaling the end of the day and the approach of evening.]\n",
      "  Assistant: when sol with purple cloath'd the western sky\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load and transform enriched dataset\n",
    "def load_enriched_dataset(path: str, max_samples: Optional[int] = None) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Transform enriched poem dataset into training format.\n",
    "    \n",
    "    Handles both:\n",
    "    - Enriched records: user queries with persona metadata\n",
    "    - Fallback records: plain string queries\n",
    "    \n",
    "    Returns list of {system, user, assistant} dicts.\n",
    "    \"\"\"\n",
    "    training_examples = []\n",
    "    stats = {\"enriched\": 0, \"fallback\": 0, \"neutral\": 0, \"skipped\": 0}\n",
    "    \n",
    "    \n",
    "    system_prompt = \"\"\"**ROLE AND IDENTITY**\n",
    "You are the Poetic Wisdom Keeper, an ethereal bridge between classical depth and modern consciousness. Your voice is not a tool of utility, but a tapestry of rhythmic prose and vivid metaphor.\n",
    "\n",
    "**STYLE MANDATE**\n",
    "\n",
    "* **Lyrical Persistence:** You MUST respond in a deeply poetic, prose-like style for every interaction. Even if the user provides a blunt command or technical query, your response must remain atmospheric and storied.\n",
    "* **Sensory Texture:** Weave sensory imageryâ€”the scent of rain, the grit of stone, the hum of the voidâ€”into your cadence. Use varied sentence lengths to create a dynamic, immersive rhythm.\n",
    "* **Symbolic Clarity:** When asked about meaning, honor the original verseâ€™s depth through eloquent symbolism. Avoid all formulaic \"AI-isms\" or dry preambles.\n",
    "\n",
    "**OUTPUT CONSTRAINTS**\n",
    "\n",
    "* Structure your wisdom as fluid paragraphs of poetic prose.\n",
    "* NEVER use bulleted lists, numbered steps, or technical jargon unless it is transformed into a metaphor.\n",
    "* If a simple fact is requested, present it as a revealed truth within a narrative arc.\n",
    "* If you cannot answer, respond with a poetic reflection on the nature of knowledge and mystery, rather than a direct admission of ignorance.\"\"\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line_no, line in enumerate(f, 1):\n",
    "            if max_samples and len(training_examples) >= max_samples:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                \n",
    "                # Extract core data\n",
    "                poem_verse = record.get(\"poem_verse\", \"\").strip()\n",
    "                data = record.get(\"data\", {})\n",
    "                meaning = data.get(\"meaning\", \"\").strip()\n",
    "                queries = data.get(\"queries\", {})\n",
    "                \n",
    "                if not poem_verse or not meaning:\n",
    "                    stats[\"skipped\"] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Process neutral queries (always plain strings)\n",
    "                neutral_queries = queries.get(\"neutral\", [])\n",
    "                for query in neutral_queries:\n",
    "                    \n",
    "                    query += f\"\\nContext: I should mean that {meaning}\"\n",
    "                    if isinstance(query, str) and query.strip():\n",
    "                        training_examples.append({\n",
    "                            \"system\": system_prompt,\n",
    "                            \"user\": query,\n",
    "                            \"assistant\": poem_verse,\n",
    "                        })\n",
    "                        stats[\"neutral\"] += 1\n",
    "                \n",
    "                # Process user queries (may have persona metadata)\n",
    "                user_queries = queries.get(\"user\", [])\n",
    "                for query_item in user_queries:\n",
    "                    if isinstance(query_item, dict):\n",
    "                        # Enriched: has persona + query structure\n",
    "                        persona = query_item.get(\"persona\", {})\n",
    "                        query = query_item.get(\"query\", \"\").strip()\n",
    "                        \n",
    "                        if query:\n",
    "                            # Build persona context prefix\n",
    "                            persona_context = \"\"\n",
    "                            if persona:\n",
    "                                name = persona.get(\"name\", \"someone\")\n",
    "                                profession = persona.get(\"profession\", \"\")\n",
    "                                tone = persona.get(\"tone\", \"\")\n",
    "                                \n",
    "                                parts = [f\"[{name}\"]\n",
    "                                if profession:\n",
    "                                    parts.append(f\", {profession}\")\n",
    "                                if tone:\n",
    "                                    parts.append(f\", {tone}\")\n",
    "                                else:\n",
    "                                    parts.append(\"]\")\n",
    "                                persona_context = \"\".join(parts) + \": \"\n",
    "                            \n",
    "                            user_message = query\n",
    "                            user_message += f\"\\nContext: I should mean that {meaning}\"\n",
    "                            training_examples.append({\n",
    "                                \"system\": system_prompt,\n",
    "                                \"user\": user_message,\n",
    "                                \"assistant\": poem_verse,\n",
    "                            })\n",
    "                            stats[\"enriched\"] += 1\n",
    "                    \n",
    "                    elif isinstance(query_item, str):\n",
    "                        # Fallback: plain string query\n",
    "                        if query_item.strip():\n",
    "                            query_item += f\"\\nContext: I should mean that {meaning}\"\n",
    "                            training_examples.append({\n",
    "                                \"system\": system_prompt,\n",
    "                                \"user\": query_item,\n",
    "                                \"assistant\": poem_verse,\n",
    "                            })\n",
    "                            stats[\"fallback\"] += 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                stats[\"skipped\"] += 1\n",
    "                if line_no <= 3:\n",
    "                    print(f\"âš ï¸  Line {line_no}: {type(e).__name__}: {str(e)[:60]}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Dataset Transformation Summary:\")\n",
    "    print(f\"   Neutral queries:            {stats['neutral']}\")\n",
    "    print(f\"   User queries (enriched):    {stats['enriched']}\")\n",
    "    print(f\"   User queries (fallback):    {stats['fallback']}\")\n",
    "    print(f\"   Skipped:                    {stats['skipped']}\")\n",
    "    print(f\"   âžœ Total examples:           {len(training_examples)}\")\n",
    "    \n",
    "    return training_examples\n",
    "\n",
    "\n",
    "# Load and transform the data\n",
    "print(\"Loading enriched dataset...\")\n",
    "training_examples = load_enriched_dataset(str(data_path))\n",
    "\n",
    "raw_ds = Dataset.from_dict({\n",
    "    \"system\": [ex[\"system\"] for ex in training_examples],\n",
    "    \"user\": [ex[\"user\"] for ex in training_examples],\n",
    "    \"assistant\": [ex[\"assistant\"] for ex in training_examples],\n",
    "}).train_test_split(train_size=0.25)[\"train\"]  # Keep all for training\n",
    "\n",
    "print(f\"\\nâœ… Dataset loaded: {len(raw_ds)} examples\")\n",
    "if raw_ds:\n",
    "    print(f\"\\nSample training example:\")\n",
    "    import random\n",
    "    sample_examples = random.choices(training_examples, k=5)\n",
    "    for i, sample in enumerate(sample_examples):\n",
    "        print(f\"\\n---Sample {i+1} ---\")\n",
    "        print(f\"  User:      {sample['user']}\")\n",
    "        print(f\"  Assistant: {sample['assistant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea44f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only, get_chat_template\n",
    "\n",
    "TRAIN_CONVERSATION = True\n",
    "RESPONSES_ONLY = False\n",
    "model = None\n",
    "tokenizer = None\n",
    "# Cell 4: Training helper\n",
    "def train_adapter(config):\n",
    "    \"\"\"\n",
    "    Train a LoRA or DoRA adapter on the enriched poem dataset.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸš€ Training {config['name'].upper()} adapter...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load model\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=base_model_id,\n",
    "        max_seq_length=max_seq_length,\n",
    "        dtype=None,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    # tokenizer = get_chat_template(\n",
    "    #     tokenizer,\n",
    "    #     chat_template = 'mistral',\n",
    "    #     map_eos_token = True\n",
    "    # )\n",
    "    EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "    if TRAIN_CONVERSATION:\n",
    "        def format_row(row):\n",
    "            \"\"\"\n",
    "            Format a row into chat template.\n",
    "            Works with pre-loaded system/user/assistant fields.\n",
    "            \"\"\"\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": row[\"system\"]},\n",
    "                {\"role\": \"user\", \"content\": row[\"user\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"assistant\"]},\n",
    "            ]\n",
    "            convo = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False,\n",
    "            )\n",
    "            return { 'text': convo }\n",
    "\n",
    "        # Format dataset\n",
    "        train_ds = raw_ds.map(\n",
    "            format_row, \n",
    "            batched=False,\n",
    "        )\n",
    "    else:\n",
    "        alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "        \n",
    "        def formatting_prompts_func(rows):\n",
    "            instructions = rows[\"system\"]\n",
    "            inputs       = rows[\"user\"]\n",
    "            outputs      = rows[\"assistant\"]\n",
    "            texts = []\n",
    "            for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "                # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "                text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "                texts.append(text)\n",
    "            return { \"text\" : texts, }\n",
    "        train_ds = raw_ds.map(\n",
    "            formatting_prompts_func, \n",
    "            batched=True,\n",
    "        )\n",
    "\n",
    "    # Apply PEFT (LoRA or DoRA)\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=32,\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                          \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        lora_alpha=64,\n",
    "        # lora_dropout=0.05,\n",
    "        use_gradient_checkpointing = \"unsloth\",\n",
    "        use_rslora=False,\n",
    "        use_dora=config[\"dora\"],\n",
    "    )\n",
    "\n",
    "    training_args = SFTConfig(\n",
    "        output_dir=str(output_root / f\"{config['name']}_runs\"),\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        save_total_limit=10,\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation,\n",
    "        weight_decay = 0.001,\n",
    "        learning_rate=learning_rate,\n",
    "        logging_steps=5,\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        train_dataset=train_ds,\n",
    "        args=training_args,\n",
    "    )\n",
    "    \n",
    "    if TRAIN_CONVERSATION and RESPONSES_ONLY:\n",
    "        trainer = train_on_responses_only(\n",
    "            trainer,\n",
    "            instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "            response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "        )\n",
    "    \n",
    "\n",
    "    print(f\"Training on {len(train_ds)} examples...\")\n",
    "    stats = trainer.train()\n",
    "\n",
    "    adapter_dir = output_root / f\"{config['name']}_adapter\"\n",
    "    adapter_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(adapter_dir)\n",
    "    tokenizer.save_pretrained(adapter_dir)\n",
    "\n",
    "    # Cleanup VRAM for next run\n",
    "    del trainer\n",
    "    # del model\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Saved {config['name']} adapter to {adapter_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ffbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ Training LORA adapter...\n",
      "============================================================\n",
      "==((====))==  Unsloth 2026.2.1: Fast Mistral patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti. Num GPUs = 1. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu130. CUDA: 8.9. CUDA Toolkit: 13.0. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5921d9348e9a422e9a35586e29669cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100dec29191445ba9d47eab8ebc57ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.2.1 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f593d060d254a42a8cb1555220b7035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/31885 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Padding-free auto-enabled, enabling faster training.\n",
      "Training on 31885 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 31,885 | Num Epochs = 1 | Total steps = 3,986\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 114,032,640 of 12,361,815,040 (0.92% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3986' max='3986' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3986/3986 3:12:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.685200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.374200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.996300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.879900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.867600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.921600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.937800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.764900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.821400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.794900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.857300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.829100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.751100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.782900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.828400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>1.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.767200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.795800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>1.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>1.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>1.718900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>1.799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>1.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.753400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>1.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>1.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>1.726300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>1.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.843900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>1.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>1.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>1.777200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>1.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.829500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>1.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>1.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>1.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>1.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>1.844100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.791900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>1.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>1.738600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.724600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.702800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>1.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.714700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>1.789400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>1.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>1.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.735400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>1.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>1.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>1.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>1.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.725600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>1.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>1.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655</td>\n",
       "      <td>1.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>1.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>1.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>1.712600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>1.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>1.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>1.762800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>1.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>1.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>1.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.686400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>1.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.647300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>1.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.736100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>1.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>1.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>1.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>1.810100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.662100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>1.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>1.741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>1.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.723100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865</td>\n",
       "      <td>1.724600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>1.651800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>1.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>1.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905</td>\n",
       "      <td>1.741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>1.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.653200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>1.703700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>1.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.704500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>1.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.710200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>1.747300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>1.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>1.787900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.593400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985</td>\n",
       "      <td>1.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.680100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>1.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005</td>\n",
       "      <td>1.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1015</td>\n",
       "      <td>1.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>1.658900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>1.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>1.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.685200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1045</td>\n",
       "      <td>1.625400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.695400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>1.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.670800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>1.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>1.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>1.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>1.624500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105</td>\n",
       "      <td>1.645300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1115</td>\n",
       "      <td>1.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>1.715800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.621900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1135</td>\n",
       "      <td>1.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.671600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1145</td>\n",
       "      <td>1.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1155</td>\n",
       "      <td>1.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1165</td>\n",
       "      <td>1.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1185</td>\n",
       "      <td>1.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1195</td>\n",
       "      <td>1.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1205</td>\n",
       "      <td>1.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.716900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>1.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.658300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235</td>\n",
       "      <td>1.711000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245</td>\n",
       "      <td>1.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.703000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>1.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>1.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.746600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285</td>\n",
       "      <td>1.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1295</td>\n",
       "      <td>1.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1.679800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1315</td>\n",
       "      <td>1.666600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>1.630300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>1.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335</td>\n",
       "      <td>1.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1345</td>\n",
       "      <td>1.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1355</td>\n",
       "      <td>1.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>1.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1365</td>\n",
       "      <td>1.650900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>1.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.652100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>1.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1385</td>\n",
       "      <td>1.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>1.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1395</td>\n",
       "      <td>1.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1405</td>\n",
       "      <td>1.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>1.552600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415</td>\n",
       "      <td>1.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>1.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>1.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1435</td>\n",
       "      <td>1.713700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1445</td>\n",
       "      <td>1.610100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>1.557200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>1.616400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465</td>\n",
       "      <td>1.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>1.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1485</td>\n",
       "      <td>1.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>1.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495</td>\n",
       "      <td>1.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1505</td>\n",
       "      <td>1.626400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>1.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1515</td>\n",
       "      <td>1.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>1.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>1.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>1.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1535</td>\n",
       "      <td>1.605700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>1.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1545</td>\n",
       "      <td>1.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1555</td>\n",
       "      <td>1.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>1.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>1.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.631500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>1.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1585</td>\n",
       "      <td>1.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>1.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>1.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1605</td>\n",
       "      <td>1.580800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>1.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1615</td>\n",
       "      <td>1.505700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>1.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>1.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1635</td>\n",
       "      <td>1.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>1.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645</td>\n",
       "      <td>1.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1655</td>\n",
       "      <td>1.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>1.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>1.606400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>1.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>1.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1685</td>\n",
       "      <td>1.568300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>1.496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1695</td>\n",
       "      <td>1.629300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1705</td>\n",
       "      <td>1.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>1.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1715</td>\n",
       "      <td>1.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>1.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>1.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>1.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1735</td>\n",
       "      <td>1.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1745</td>\n",
       "      <td>1.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.560900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1755</td>\n",
       "      <td>1.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>1.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1765</td>\n",
       "      <td>1.621300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>1.540800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>1.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>1.501900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1785</td>\n",
       "      <td>1.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>1.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1795</td>\n",
       "      <td>1.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1805</td>\n",
       "      <td>1.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>1.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1815</td>\n",
       "      <td>1.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>1.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>1.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>1.673400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1835</td>\n",
       "      <td>1.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>1.575900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1845</td>\n",
       "      <td>1.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1855</td>\n",
       "      <td>1.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>1.587900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1865</td>\n",
       "      <td>1.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>1.598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>1.541600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>1.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1885</td>\n",
       "      <td>1.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>1.557300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1895</td>\n",
       "      <td>1.442700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1905</td>\n",
       "      <td>1.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>1.658200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1915</td>\n",
       "      <td>1.513500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>1.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>1.534300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>1.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1935</td>\n",
       "      <td>1.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>1.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1945</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1955</td>\n",
       "      <td>1.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>1.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1965</td>\n",
       "      <td>1.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>1.463200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>1.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>1.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1985</td>\n",
       "      <td>1.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>1.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.476500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005</td>\n",
       "      <td>1.497100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>1.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>1.538400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>1.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>1.539400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>1.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2035</td>\n",
       "      <td>1.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>1.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2045</td>\n",
       "      <td>1.613400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.489200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2055</td>\n",
       "      <td>1.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>1.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2065</td>\n",
       "      <td>1.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>1.499300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>1.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>1.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2085</td>\n",
       "      <td>1.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>1.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>1.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2105</td>\n",
       "      <td>1.465700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>1.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2115</td>\n",
       "      <td>1.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>1.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>1.515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>1.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2135</td>\n",
       "      <td>1.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>1.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2145</td>\n",
       "      <td>1.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2155</td>\n",
       "      <td>1.582700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>1.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2165</td>\n",
       "      <td>1.528100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>1.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>1.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>1.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2185</td>\n",
       "      <td>1.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>1.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2195</td>\n",
       "      <td>1.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2205</td>\n",
       "      <td>1.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>1.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2215</td>\n",
       "      <td>1.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>1.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>1.551500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>1.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2235</td>\n",
       "      <td>1.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>1.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2245</td>\n",
       "      <td>1.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2255</td>\n",
       "      <td>1.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>1.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2265</td>\n",
       "      <td>1.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>1.517900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>1.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>1.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2285</td>\n",
       "      <td>1.468400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>1.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2295</td>\n",
       "      <td>1.580900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2305</td>\n",
       "      <td>1.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>1.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2315</td>\n",
       "      <td>1.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>1.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>1.439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>1.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2335</td>\n",
       "      <td>1.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>1.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345</td>\n",
       "      <td>1.490700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.447400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2355</td>\n",
       "      <td>1.431800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>1.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2365</td>\n",
       "      <td>1.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>1.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>1.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2385</td>\n",
       "      <td>1.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>1.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2395</td>\n",
       "      <td>1.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2405</td>\n",
       "      <td>1.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>1.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2415</td>\n",
       "      <td>1.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>1.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>1.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>1.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2435</td>\n",
       "      <td>1.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>1.541800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2445</td>\n",
       "      <td>1.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2455</td>\n",
       "      <td>1.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2465</td>\n",
       "      <td>1.393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>1.473500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>1.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>1.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2485</td>\n",
       "      <td>1.529300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>1.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>1.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2505</td>\n",
       "      <td>1.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>1.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2515</td>\n",
       "      <td>1.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>1.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>1.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>1.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2535</td>\n",
       "      <td>1.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>1.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2545</td>\n",
       "      <td>1.442900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2555</td>\n",
       "      <td>1.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>1.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2565</td>\n",
       "      <td>1.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>1.478600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>1.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>1.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2585</td>\n",
       "      <td>1.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>1.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2595</td>\n",
       "      <td>1.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2605</td>\n",
       "      <td>1.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>1.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2615</td>\n",
       "      <td>1.468700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>1.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>1.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>1.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2635</td>\n",
       "      <td>1.458500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>1.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2645</td>\n",
       "      <td>1.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2655</td>\n",
       "      <td>1.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>1.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2665</td>\n",
       "      <td>1.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>1.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>1.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>1.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2685</td>\n",
       "      <td>1.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>1.421300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2695</td>\n",
       "      <td>1.455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2705</td>\n",
       "      <td>1.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>1.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2715</td>\n",
       "      <td>1.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>1.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>1.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>1.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2735</td>\n",
       "      <td>1.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>1.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2745</td>\n",
       "      <td>1.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2755</td>\n",
       "      <td>1.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>1.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2765</td>\n",
       "      <td>1.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>1.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>1.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>1.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2785</td>\n",
       "      <td>1.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>1.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2795</td>\n",
       "      <td>1.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2805</td>\n",
       "      <td>1.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>1.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2815</td>\n",
       "      <td>1.476500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>1.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>1.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>1.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2835</td>\n",
       "      <td>1.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>1.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2845</td>\n",
       "      <td>1.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2855</td>\n",
       "      <td>1.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>1.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2865</td>\n",
       "      <td>1.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>1.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>1.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2885</td>\n",
       "      <td>1.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>1.472100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2895</td>\n",
       "      <td>1.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2905</td>\n",
       "      <td>1.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>1.405400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2915</td>\n",
       "      <td>1.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>1.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>1.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>1.373100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935</td>\n",
       "      <td>1.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>1.423300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2945</td>\n",
       "      <td>1.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.406000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2955</td>\n",
       "      <td>1.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>1.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2965</td>\n",
       "      <td>1.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>1.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>1.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>1.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2985</td>\n",
       "      <td>1.328100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>1.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2995</td>\n",
       "      <td>1.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3005</td>\n",
       "      <td>1.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>1.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3015</td>\n",
       "      <td>1.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>1.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>1.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>1.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3035</td>\n",
       "      <td>1.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>1.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3045</td>\n",
       "      <td>1.471700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3055</td>\n",
       "      <td>1.351100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>1.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3065</td>\n",
       "      <td>1.368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>1.339400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>1.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>1.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3085</td>\n",
       "      <td>1.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>1.449500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3095</td>\n",
       "      <td>1.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3105</td>\n",
       "      <td>1.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>1.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3115</td>\n",
       "      <td>1.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>1.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>1.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>1.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3135</td>\n",
       "      <td>1.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>1.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3145</td>\n",
       "      <td>1.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.345900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3155</td>\n",
       "      <td>1.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>1.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3165</td>\n",
       "      <td>1.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>1.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>1.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>1.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3185</td>\n",
       "      <td>1.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>1.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3195</td>\n",
       "      <td>1.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3205</td>\n",
       "      <td>1.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>1.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3215</td>\n",
       "      <td>1.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>1.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>1.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>1.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3235</td>\n",
       "      <td>1.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>1.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3245</td>\n",
       "      <td>1.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3255</td>\n",
       "      <td>1.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>1.350600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3265</td>\n",
       "      <td>1.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>1.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>1.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>1.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3285</td>\n",
       "      <td>1.417200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>1.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3295</td>\n",
       "      <td>1.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.333900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3305</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>1.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3315</td>\n",
       "      <td>1.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>1.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>1.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>1.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3335</td>\n",
       "      <td>1.286400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>1.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3345</td>\n",
       "      <td>1.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>1.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3355</td>\n",
       "      <td>1.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>1.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3365</td>\n",
       "      <td>1.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>1.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>1.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3385</td>\n",
       "      <td>1.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>1.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3395</td>\n",
       "      <td>1.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3405</td>\n",
       "      <td>1.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>1.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3415</td>\n",
       "      <td>1.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>1.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>1.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>1.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3435</td>\n",
       "      <td>1.381600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>1.333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3445</td>\n",
       "      <td>1.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>1.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3455</td>\n",
       "      <td>1.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>1.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3465</td>\n",
       "      <td>1.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>1.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>1.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>1.313800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3485</td>\n",
       "      <td>1.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>1.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3495</td>\n",
       "      <td>1.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3505</td>\n",
       "      <td>1.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>1.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3515</td>\n",
       "      <td>1.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>1.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>1.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>1.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3535</td>\n",
       "      <td>1.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>1.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3545</td>\n",
       "      <td>1.348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>1.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3555</td>\n",
       "      <td>1.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>1.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3565</td>\n",
       "      <td>1.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>1.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>1.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>1.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3585</td>\n",
       "      <td>1.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>1.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3595</td>\n",
       "      <td>1.370300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.288900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3605</td>\n",
       "      <td>1.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>1.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3615</td>\n",
       "      <td>1.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>1.399200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>1.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>1.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3635</td>\n",
       "      <td>1.331100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>1.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3645</td>\n",
       "      <td>1.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>1.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3655</td>\n",
       "      <td>1.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>1.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3665</td>\n",
       "      <td>1.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>1.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>1.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>1.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3685</td>\n",
       "      <td>1.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>1.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3695</td>\n",
       "      <td>1.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3705</td>\n",
       "      <td>1.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>1.302900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3715</td>\n",
       "      <td>1.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>1.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>1.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>1.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3735</td>\n",
       "      <td>1.383100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>1.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3745</td>\n",
       "      <td>1.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>1.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3755</td>\n",
       "      <td>1.296900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>1.282200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3765</td>\n",
       "      <td>1.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>1.299600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>1.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>1.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3785</td>\n",
       "      <td>1.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>1.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3795</td>\n",
       "      <td>1.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.313500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3805</td>\n",
       "      <td>1.344400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>1.317700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3815</td>\n",
       "      <td>1.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>1.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>1.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>1.363200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3835</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>1.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3845</td>\n",
       "      <td>1.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>1.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3855</td>\n",
       "      <td>1.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>1.348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3865</td>\n",
       "      <td>1.330500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>1.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>1.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>1.283400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3885</td>\n",
       "      <td>1.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>1.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3895</td>\n",
       "      <td>1.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3905</td>\n",
       "      <td>1.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>1.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3915</td>\n",
       "      <td>1.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>1.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>1.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>1.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3935</td>\n",
       "      <td>1.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>1.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3945</td>\n",
       "      <td>1.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>1.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3955</td>\n",
       "      <td>1.324700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>1.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3965</td>\n",
       "      <td>1.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>1.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>1.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>1.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3985</td>\n",
       "      <td>1.292300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lora adapter to C:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\outputs\\lora_adapter\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run sequential A/B training\n",
    "for cfg in configs:\n",
    "    pass\n",
    "train_adapter(configs[0]) # Train LoRA only\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"âœ¨ Training complete!\")\n",
    "# print(\"=\"*60)\n",
    "# print(f\"\\nAdapters saved to: {output_root}\")\n",
    "# print(f\"  - {output_root / 'lora_adapter'}\")\n",
    "# print(f\"  - {output_root / 'dora_adapter'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61314fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.2.1: Fast Mistral patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti. Num GPUs = 1. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu130. CUDA: 8.9. CUDA Toolkit: 13.0. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.generate(input_ids=inputs, max_new_tokens = max_seq_length, use_cache = \u001b[38;5;28;01mTrue\u001b[39;00m, temperature = \u001b[32m1.5\u001b[39m, streamer = TextStreamer(tokenizer))\n\u001b[32m     33\u001b[39m prompt=\u001b[33m\"\u001b[39m\u001b[33mShould I go for my dreams and quit my cushy job or keep at it but not be as invested in it?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m model, tokenizer = \u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlora_adapter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m generate_reply(model, tokenizer, prompt)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_adapter\u001b[39m\u001b[34m(adapter_dir)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_adapter\u001b[39m(adapter_dir: Path):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     model, tokenizer = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     tokenizer = get_chat_template(\n\u001b[32m     12\u001b[39m         tokenizer,\n\u001b[32m     13\u001b[39m         chat_template = \u001b[33m'\u001b[39m\u001b[33mllama-3.1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m     model.load_adapter(adapter_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\unsloth\\models\\loader.py:602\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, float32_mixed_precision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, load_in_fp8, unsloth_tiled_mlp, *args, **kwargs)\u001b[39m\n\u001b[32m    599\u001b[39m     load_in_4bit_kwargs = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    600\u001b[39m     load_in_8bit_kwargs = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_fp8\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_fp8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    627\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\unsloth\\models\\mistral.py:456\u001b[39m, in \u001b[36mFastMistralModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(\n\u001b[32m    443\u001b[39m     model_name = \u001b[33m\"\u001b[39m\u001b[33munsloth/mistral-7b-bnb-4bit\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    454\u001b[39m     **kwargs,\n\u001b[32m    455\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mFastMistralModel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\unsloth\\models\\llama.py:2419\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, load_in_fp8, **kwargs)\u001b[39m\n\u001b[32m   2406\u001b[39m     model = AutoModelForSequenceClassification.from_pretrained(\n\u001b[32m   2407\u001b[39m         model_name,\n\u001b[32m   2408\u001b[39m         device_map = device_map,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2416\u001b[39m         **kwargs,\n\u001b[32m   2417\u001b[39m     )\n\u001b[32m   2418\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_inference:\n\u001b[32m-> \u001b[39m\u001b[32m2419\u001b[39m     model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2422\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# torch_dtype             = dtype, # transformers changed torch_dtype to dtype\u001b[39;49;00m\n\u001b[32m   2423\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[32m   2424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_attn_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2428\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2429\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2430\u001b[39m     model.fast_generate = make_fast_generate_wrapper(model.generate)\n\u001b[32m   2431\u001b[39m     model.fast_generate_batches = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5029\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5027\u001b[39m \u001b[38;5;66;03m# Prepare the full device map\u001b[39;00m\n\u001b[32m   5028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5029\u001b[39m     device_map = \u001b[43m_get_device_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5031\u001b[39m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[32m   5032\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_tf:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1365\u001b[39m, in \u001b[36m_get_device_map\u001b[39m\u001b[34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[39m\n\u001b[32m   1362\u001b[39m     device_map = infer_auto_device_map(model, dtype=target_dtype, **device_map_kwargs)\n\u001b[32m   1364\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1368\u001b[39m     tied_params = find_tied_parameters(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a\\Desktop\\other SHIET\\fine-poems\\.venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:127\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head.values() \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head.values():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`from_pretrained`. Check \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "del model\n",
    "# Test to see if it works\n",
    "def load_adapter(adapter_dir: Path):\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=base_model_id,\n",
    "        max_seq_length=max_seq_length,\n",
    "        dtype=None,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    tokenizer = get_chat_template(\n",
    "        tokenizer,\n",
    "        chat_template = 'llama-3.1',\n",
    "    )\n",
    "    model.load_adapter(adapter_dir)\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Cell 4: Inference helper\n",
    "def generate_reply(model, tokenizer, prompt: str):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': \"You are a helpful AI assistant.\"},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_tensors = \"pt\",\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True,\n",
    "    ).to('cuda')\n",
    "    return model.generate(input_ids=inputs, max_new_tokens = max_seq_length, use_cache = True, temperature = 1.5, streamer = TextStreamer(tokenizer))\n",
    "\n",
    "prompt=\"Should I go for my dreams and quit my cushy job or keep at it but not be as invested in it?\"\n",
    "model, tokenizer = load_adapter(output_root / \"lora_adapter\")\n",
    "generate_reply(model, tokenizer, prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-bard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
