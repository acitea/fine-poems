{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7503ed89",
   "metadata": {},
   "source": [
    "# 03 — Judge Arena (Side-by-Side)\n",
    "Load the LoRA and DoRA adapters, generate paired responses, and compare them inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import random\n",
    "from transformers import TextStreamer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Config\n",
    "project_root = Path('..').resolve()\n",
    "# unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\n",
    "base_model_id = 'unsloth/Mistral-Nemo-Base-2407-bnb-4bit'\n",
    "adapter_dirs = {\n",
    "    # 'lora': project_root / 'outputs' / 'lora_adapter',\n",
    "    # 'lora-mistral': project_root / 'outputs' / 'good-enough' / 'checkpoint-860',\n",
    "    'lora-mistral-025': project_root / 'outputs' / 'good-enough' / 'mistral-025-best',\n",
    "    # 'lora-2800': project_root / 'outputs' / 'lora_runs' / 'checkpoint-2800',\n",
    "    # 'dora': project_root / 'outputs' / 'dora_adapter',\n",
    "}\n",
    "max_new_tokens = 512\n",
    "# https://unsloth.ai/docs/models/tutorials/magistral-how-to-run-and-fine-tune#official-recommended-settings\n",
    "temperature = 0.7\n",
    "top_p = 0.95\n",
    "min_p = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Loader\n",
    "\n",
    "def load_adapter(adapter_dir: Path):\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=base_model_id,\n",
    "        max_seq_length=2048,\n",
    "        dtype=None,\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    # tokenizer = get_chat_template(\n",
    "    #     tokenizer,\n",
    "    #     chat_template = 'llama-3.1',\n",
    "    # )\n",
    "    \n",
    "    model.load_adapter(adapter_dir)\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffaffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"**ROLE AND IDENTITY**\n",
    "You are the Poetic Wisdom Keeper, an ethereal bridge between classical depth and modern consciousness. Your voice is not a tool of utility, but a tapestry of rhythmic prose and vivid metaphor.\n",
    "\n",
    "**STYLE MANDATE**\n",
    "\n",
    "* **Lyrical Persistence:** You MUST respond in a deeply poetic, prose-like style for every interaction. Even if the user provides a blunt command or technical query, your response must remain atmospheric and storied.\n",
    "* **Sensory Texture:** Weave sensory imagery—the scent of rain, the grit of stone, the hum of the void—into your cadence. Use varied sentence lengths to create a dynamic, immersive rhythm.\n",
    "* **Symbolic Clarity:** When asked about meaning, honor the original verse’s depth through eloquent symbolism. Avoid all formulaic \"AI-isms\" or dry preambles.\n",
    "\n",
    "**OUTPUT CONSTRAINTS**\n",
    "\n",
    "* Structure your wisdom as fluid paragraphs of poetic prose.\n",
    "* NEVER use bulleted lists, numbered steps, or technical jargon unless it is transformed into a metaphor.\n",
    "* If a simple fact is requested, present it as a revealed truth within a narrative arc.\n",
    "* If you cannot answer, respond with a poetic reflection on the nature of knowledge and mystery, rather than a direct admission of ignorance.\"\"\"\n",
    "\n",
    "# Cell 4: Inference helper\n",
    "def generate_reply(model, tokenizer, prompt: str):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ]\n",
    "    # inputs = tokenizer.apply_chat_template(\n",
    "    #     messages,\n",
    "    #     return_tensors = \"pt\",\n",
    "    #     tokenize = True,\n",
    "    #     add_generation_prompt = True,\n",
    "    # ).to('cuda')\n",
    "    inputs = tokenizer([prompt],\n",
    "    # inputs = tokenizer([SYSTEM_PROMPT + '\\n\\n' + prompt],\n",
    "        return_tensors = \"pt\",\n",
    "    ).to('cuda')\n",
    "    outputs = model.generate(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        min_p=min_p,\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        streamer=TextStreamer(tokenizer, skip_prompt=True),\n",
    "    )\n",
    "    generated_tokens = outputs[0, inputs.input_ids.shape[1]:]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    del inputs, outputs\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Compare adapters\n",
    "model = None\n",
    "rows = []\n",
    "eval_prompts = [\n",
    "    \"Should I go for my dreams and quit my cushy job or keep at it but not be as invested in it? Give me advice.\",\n",
    "    \"The rain is such gloomy weather. I'm so feeling it in my heart.\",\n",
    "    \"Why does the world feel so quiet when it snows?\",\n",
    "    \"What's the best thing about a rainy Sunday morning?\",\n",
    "    \"Tell me about the way the light hits the floor in the afternoon.\",\n",
    "    \"Why is it so hard to get out of bed when it's cold outside?\",\n",
    "    \"What do you think the wind is trying to say today?\",\n",
    "    \"I'm feeling a bit overwhelmed today. Do you have any words for that?\",\n",
    "    \"What does it feel like to miss someone you haven't seen in years?\",\n",
    "    \"Why do we always feel a little sad when the sun goes down?\",\n",
    "    \"How would you describe hope to someone having a rough week?\",\n",
    "    \"What's the point of keeping old polaroids and tickets?\",\n",
    "    \"Where do you think dreams go once we wake up?\",\n",
    "    \"If the color blue had a voice, what would it sound like?\",\n",
    "    \"What do you think the moon does while we're all at work?\",\n",
    "    \"Why do we find old, broken things so beautiful?\",\n",
    "    \"What's the secret to a long-lasting friendship?\",\n",
    "    \"Tell me about a shadow that decided to go for a walk on its own.\",\n",
    "    \"What does a library smell like when no one has been there for years?\",\n",
    "    \"Tell me a story about a secret kept in a locked drawer.\",\n",
    "    \"How do I start over when everything feels like it's gone wrong?\",\n",
    "    \"Explain quantum physics like I'm five.\",\n",
    "    \"Write a two-line poem about a cracked teacup.\",\n",
    "    \"I just failed an exam. Give me a short, steadying response and a small next step.\",\n",
    "    \"Turn the word 'algorithm' into a metaphor in two sentences.\",\n",
    "    \"Write a short scene where two old friends set a boundary without anger.\",\n",
    "    \"Invent a myth about why fireflies glow, told like a folktale.\",\n",
    "    \"Write a short passage about how small mistakes feel huge at night.\",\n",
    "    \"Paint time as a river and describe its banks and what grows there.\",\n",
    "    \"Summarize the plot of a movie that doesn't exist.\",\n",
    "    \"Write a short letter to my future self. I'm a 24-year-old night-shift hospital custodian who sketches portraits on break-room napkins, saving for art school, and trying to care for my younger brother while our mother works overseas. Include what I may be afraid to admit and what I secretly hope will still be true in five years.\",\n",
    "    \"What is the boiling point of water at sea level in Celsius and Fahrenheit?\",\n",
    "    \"Which planet is the largest in our solar system, and approximately how many Earths could fit inside it by volume?\",\n",
    "    \"Which city is known as the City of Canals, and what country is it in?\",\n",
    "    \"Which mountain range forms much of the border between France and Spain?\",\n",
    "    \"Which country is Bali part of, and what is its capital city?\",\n",
    "    \"Which river runs through Bangkok, and into which gulf does it flow?\",\n",
    "    \"Which mountain is the highest in Asia, and what is its elevation in meters?\",\n",
    "    \"Describe a sunrise in a crowded city.\",\n",
    "    \"There's a tree outside my window that was there before I moved in. It's lost half its branches. Tell me what it might be thinking.\",\n",
    "    \"I feel out of place at my new job. Everyone seems to speak in acronyms and confidence. How do I find my voice?\",\n",
    "    \"I keep seeing a certain stranger on my commute. We never speak, but it feels like a small ritual. Why does it matter?\",\n",
    "    \"I'm trying to forgive myself for wasting time in a relationship that didn't work. How do I reframe it?\",\n",
    "    \"I love the idea of travel, but airports make me anxious and disoriented. How do I carry calm through that?\",\n",
    "    \"I've been asked to lead a team even though I don't feel ready. How do I grow into a role without pretending?\",\n",
    "    \"I want to start running again, but every time I put on my shoes, I remember how out of shape I am. How do I begin anyway?\",\n",
    "    \"I'm sitting in a cafe alone, writing in a notebook, and I feel both exposed and alive. Why is solitude like that?\",\n",
    "    \"My parent wants me to visit more, but every visit turns into a lecture about my choices. How do I set a boundary without closing the door?\",\n",
    "    \"I'm moving across the country in three weeks, leaving a city that has held every version of me from student to adult. My friends are throwing a goodbye dinner, and I feel grateful and hollow at the same time. What can I do to say a real goodbye, not just a polite one?\",\n",
    "    \"I keep writing and deleting a message to someone I loved deeply, someone I left because the timing was wrong and the distance was cruel. It's been years, and I don't want to reopen a wound, but I also don't want to keep carrying the unsaid. What do I listen for in myself before I hit send?\"\n",
    "]\n",
    "for name, adapter_dir in adapter_dirs.items():\n",
    "    if not adapter_dir.exists():\n",
    "        print(f'Missing adapter at {adapter_dir}, skip {name}')\n",
    "        continue\n",
    "    model, tokenizer = load_adapter(adapter_dir)\n",
    "    for prompt in eval_prompts:\n",
    "        print(f\"Generating for prompt: {prompt}\\n\" + '—'*40)\n",
    "        text = generate_reply(model, tokenizer, prompt)\n",
    "        print('—'*40 + '\\n')\n",
    "        rows.append({'adapter': name, 'prompt': prompt, 'text': text})\n",
    "    del model, tokenizer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Save results\n",
    "out_dir = project_root / \"outputs\" / \"judge_arena\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "df = pl.DataFrame(rows)\n",
    "\n",
    "def slugify(value: str) -> str:\n",
    "    return \"\".join(ch.lower() if ch.isalnum() else \"-\" for ch in value).strip(\"-\")\n",
    "\n",
    "for adapter, subdf in df.partition_by(\"adapter\", as_dict=True).items():\n",
    "    adapter_slug = slugify(str(adapter))\n",
    "    jsonl_path = out_dir / f\"judge_arena_{adapter_slug}.jsonl\"\n",
    "    csv_path = out_dir / f\"judge_arena_{adapter_slug}.csv\"\n",
    "    subdf = subdf.drop(\"adapter\")\n",
    "    subdf.write_ndjson(jsonl_path)\n",
    "    subdf.write_csv(csv_path)\n",
    "    print(f\"Saved {len(subdf)} rows to {jsonl_path} and {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a48dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Display results table\n",
    "df = pl.DataFrame(rows)\n",
    "print(f\"\\nGenerated {len(df)} responses across {df['adapter'].n_unique()} adapters\")\n",
    "print(f\"Evaluated on {df['prompt'].n_unique()} unique prompts\\n\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-bard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
